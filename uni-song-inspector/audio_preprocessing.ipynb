{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 16:08:22.561401: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-02 16:08:23.024221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-02 16:08:23.024258: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-02 16:08:23.088235: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-02 16:08:24.221137: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-02 16:08:24.221347: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-02 16:08:24.221369: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import librosa\n",
    "import tqdm\n",
    "import time \n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def alert():\n",
    "    duration = 1  # seconds\n",
    "    freq = 440  # Hz\n",
    "\n",
    "    for i in range(2):\n",
    "        os.system('play -nq -t alsa synth {} sine {}'.format(duration, freq))\n",
    "    os.system('spd-say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-E1-Major 00.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-E1-Major 01.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-E1-Major 02.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-E1-Major 03.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-E1-Major 04.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FileName         Class\n",
       "0  1-E1-Major 00.wav  Sound_Guitar\n",
       "1  1-E1-Major 01.wav  Sound_Guitar\n",
       "2  1-E1-Major 02.wav  Sound_Guitar\n",
       "3  1-E1-Major 03.wav  Sound_Guitar\n",
       "4  1-E1-Major 04.wav  Sound_Guitar"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('/home/michael/Documents/VScode/Uni/Advanced AI/project_ideas/archive/Metadata_Train.csv')\n",
    "test_csv = pd.read_csv('/home/michael/Documents/VScode/Uni/Advanced AI/project_ideas/archive/Metadata_Test.csv')\n",
    "train_csv.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13857/4148017990.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm.tqdm_notebook(train_csv.iterrows(), desc = 'tqdm() Progress Bar', total = len(train_csv)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780a66e6030c4c92aa42cda2d936f35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tqdm() Progress Bar:   0%|          | 0/2629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_windows(audio, window_size = 22050):\n",
    "    \n",
    "    start = 0\n",
    "    windows = []\n",
    "    audio_len = len(audio)\n",
    "    \n",
    "    while start < audio_len:\n",
    "        \n",
    "        #find window end\n",
    "        if start+window_size > audio_len:\n",
    "            break\n",
    "        else: \n",
    "            window_end = int(start + window_size)\n",
    "        #take window \n",
    "        windows.append(audio[start:window_end])\n",
    "        #move window\n",
    "        start += int(window_size / 2) \n",
    "      \n",
    "    #stretch any windows the wrong size\n",
    "    #window stretching appears not to work for now just discard any windows that are too small\n",
    "    # for index, window in enumerate(windows):\n",
    "    #     if  len(window) != window_size:\n",
    "    #         rate = 1/(window_size / len(window))\n",
    "    #         windows[index] = librosa.effects.time_stretch(y = window, rate=rate)\n",
    "        \n",
    "        \n",
    "    return windows\n",
    "\n",
    "training_data = {'mel spec ref' : [], 'instrument' : []}\n",
    "os.system('spd-say \"I am ready for your load baby, bring it on\"')\n",
    "for index, row in tqdm.tqdm_notebook(train_csv.iterrows(), desc = 'tqdm() Progress Bar', total = len(train_csv)):\n",
    "    \n",
    "    filename = row['FileName']\n",
    "    audio, sr = librosa.load(path = f'/home/michael/Documents/VScode/Uni/Advanced AI/project_ideas/archive/Train_submission/Train_submission/{filename}')\n",
    "    windowed_audio = get_windows(audio)\n",
    "    \n",
    "    for index_au, audio_window in enumerate(windowed_audio):\n",
    "        \n",
    "        mel = librosa.feature.melspectrogram(y=audio_window, sr=sr)\n",
    "        mel_to_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        flat_mel_spec = mel_to_db.flatten()\n",
    "        \n",
    "        filename = f'{index}{index_au}.txt'\n",
    "        np.savetxt(f'./train_mel_spec/{filename}', flat_mel_spec)\n",
    "        \n",
    "        training_data['mel spec ref'].append(filename)\n",
    "        training_data['instrument'].append(row['Class'])\n",
    "        \n",
    "df = pd.DataFrame.from_dict(training_data)\n",
    "df.to_csv('training_data.csv')\n",
    "    \n",
    "os.system('spd-say \"test data has compiled\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13857/2042231475.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm.tqdm_notebook(test_csv.iterrows(), desc = 'tqdm() Progress Bar', total = len(test_csv)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa507a23c56143ad956b60957c1b84e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tqdm() Progress Bar:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.system('spd-say \"awwh yeah, I am done baby I am ready for your next load\"')\n",
    "\n",
    "\n",
    "test_data = {'mel spec ref' : [], 'instrument' : []}\n",
    "\n",
    "for index, row in tqdm.tqdm_notebook(test_csv.iterrows(), desc = 'tqdm() Progress Bar', total = len(test_csv)):\n",
    "    \n",
    "    filename = row['FileName']\n",
    "    audio, sr = librosa.load(path = f'/home/michael/Documents/VScode/Uni/Advanced AI/project_ideas/archive/Test_submission/Test_submission/{filename}')\n",
    "    windowed_audio = get_windows(audio, sr)\n",
    "    \n",
    "    for index_au, audio_window in enumerate(windowed_audio):\n",
    "        \n",
    "        mel = librosa.feature.melspectrogram(y=audio_window, sr=sr)\n",
    "        mel_to_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        flat_mel_spec = mel_to_db.flatten()\n",
    "        \n",
    "        filename = f'{index}{index_au}.txt'\n",
    "        np.savetxt(f'./test_mel_spec/{filename}', flat_mel_spec)\n",
    "        \n",
    "        test_data['mel spec ref'].append(filename)\n",
    "        test_data['instrument'].append(row['Class'])\n",
    "        \n",
    "     \n",
    "df = pd.DataFrame.from_dict(test_data)\n",
    "df.to_csv('test_data.csv')\n",
    "\n",
    "alert()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
