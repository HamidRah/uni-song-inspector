{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "import librosa\n",
    "from keras_tuner import RandomSearch, HyperParameters, BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('training_data.csv')\n",
    "test_csv = pd.read_csv('test_data.csv')\n",
    "\n",
    "labels = train_csv['instrument'].unique()\n",
    "#spelling error in the test_data we need to account for\n",
    "label_encoder = {'Sound_Guiatr' : 0}\n",
    "for index, label in enumerate(labels):\n",
    "    label_encoder[label] = index\n",
    "\n",
    "print(labels)\n",
    "train_csv['instrument'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing our data has survived\n",
    "train_csv.head()\n",
    "flat_mel_spec = np.loadtxt(f'./train_mel_spec/00.txt')\n",
    "mel_spec = flat_mel_spec.reshape(128,44)\n",
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "librosa.display.specshow(mel_spec, sr=22050, x_axis='time', y_axis='mel')\n",
    "plt.title('pls work')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing training data\n",
    "\n",
    "guitar_df = train_csv[train_csv['instrument'] == 'Sound_Guitar']\n",
    "piano_df = train_csv[train_csv['instrument'] == 'Sound_Drum']\n",
    "drum_df = train_csv[train_csv['instrument'] == 'Sound_Violin']\n",
    "violin_df = train_csv[train_csv['instrument'] == 'Sound_Piano']\n",
    "\n",
    "#750 examples from each for intail training\n",
    "data_combind_train_validation = guitar_df['mel spec ref'].tolist()[:750]\n",
    "labels_combind_train_validation = guitar_df['instrument'].tolist()[:750]\n",
    "\n",
    "data_combind_train_validation.extend(piano_df['mel spec ref'].tolist()[:750])\n",
    "labels_combind_train_validation.extend(piano_df['instrument'].tolist()[:750])\n",
    "\n",
    "data_combind_train_validation.extend(drum_df['mel spec ref'].tolist()[:750])\n",
    "labels_combind_train_validation.extend(drum_df['instrument'].tolist()[:750])\n",
    "\n",
    "data_combind_train_validation.extend(violin_df['mel spec ref'].tolist()[:750])\n",
    "labels_combind_train_validation.extend(violin_df['instrument'].tolist()[:750])\n",
    "\n",
    "\n",
    "#mel spec data and reshape it\n",
    "for index, data in enumerate(data_combind_train_validation): \n",
    "    data_combind_train_validation[index] = np.loadtxt(f'./train_mel_spec/{data}').reshape((128, 44))\n",
    " \n",
    "#change labels to 0-4   \n",
    "for index, data in enumerate(labels_combind_train_validation):\n",
    "    labels_combind_train_validation[index] = label_encoder[data]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the conversion has worked\n",
    "plt.figure(figsize=(14,5))\n",
    "librosa.display.specshow(data_combind_train_validation[0], sr=22050, x_axis='time', y_axis='mel')\n",
    "plt.title(labels_combind_train_validation[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv['instrument'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spelling mistake in test data - should be guitar not guiatr\n",
    "guitar_df = test_csv[test_csv['instrument'] == 'Sound_Guiatr']\n",
    "piano_df = test_csv[test_csv['instrument'] == 'Sound_Drum']\n",
    "drum_df = test_csv[test_csv['instrument'] == 'Sound_Violin']\n",
    "violin_df = test_csv[test_csv['instrument'] == 'Sound_Piano']\n",
    "\n",
    "data_test = guitar_df['mel spec ref'].tolist()\n",
    "labels_test = guitar_df['instrument'].tolist()\n",
    "\n",
    "data_test.extend(piano_df['mel spec ref'].tolist())\n",
    "labels_test.extend(piano_df['instrument'].tolist())\n",
    "\n",
    "data_test.extend(drum_df['mel spec ref'].tolist())\n",
    "labels_test.extend(drum_df['instrument'].tolist())\n",
    "\n",
    "data_test.extend(violin_df['mel spec ref'].tolist())\n",
    "labels_test.extend(violin_df['instrument'].tolist())\n",
    "\n",
    "#mel spec data and reshape it\n",
    "for index, data in enumerate(data_test): \n",
    "    data_test[index] = np.loadtxt(f'./test_mel_spec/{data}').reshape((128, 44))\n",
    " \n",
    "#change labels to 0-4   \n",
    "for index, data in enumerate(labels_test):\n",
    "    labels_test[index] = label_encoder[data]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(history,y_pred,y_true):\n",
    "    plt.plot(history.epoch, history.history[\"accuracy\"],history.history['val_accuracy'])\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.suptitle('Training (blue) and validation (orange) History')\n",
    "    plt.show()\n",
    "    \n",
    "    predicted= np.argmax(y_pred,axis=1)\n",
    "    actual = np.argmax(y_true, axis=1)\n",
    "    print(f'Test Accuracy {accuracy_score(actual, predicted) * 100}%')\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(actual, predicted)\n",
    "    \n",
    "    #,display_labels=train_csv['instrument'].unique()) \n",
    "\n",
    "x_train,x_val,y_train,y_val= train_test_split(data_combind_train_validation, labels_combind_train_validation,\n",
    "                                                test_size=0.125,\n",
    "                                                shuffle=True,\n",
    "                                                stratify=labels_combind_train_validation)\n",
    "\n",
    "def build_model(hp: HyperParameters):\n",
    "    with tf.device('/CPU:0'):\n",
    "        input_shape=(128,44,1)\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(hp.Int('conv_1_units', min_value=32, max_value=128, step=32), (5, 5), activation='relu', input_shape=input_shape))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Conv2D(hp.Int('conv_2_units', min_value=32, max_value=128, step=32), (5, 5), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Conv2D(hp.Int('conv_3_units', min_value=32, max_value=128, step=32), (5, 5), activation='relu'))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(hp.Int('dense_1_units', min_value=32, max_value=128, step=32), activation='relu'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Dense(hp.Int('dense_2_units', min_value=32, max_value=128, step=32), activation='relu'))\n",
    "        model.add(layers.Dense(4, activation='softmax'))\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                      metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=4,\n",
    "    executions_per_trial=2,\n",
    "    directory='bayesian_optimization',\n",
    "    project_name='audio_cnn'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# tuner.search(np.array(x_train), np.array(y_train),\n",
    "#                  epochs=10, validation_data=(np.array(x_val), np.array(y_val)))\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    tuner.search(np.array(x_train), np.array(y_train),\n",
    "                 epochs=10, validation_data=(np.array(x_val), np.array(y_val)))\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "# model = tuner.hypermodel.build(best_hps)\n",
    "# history = model.fit(np.array(x_train), np.array(y_train),\n",
    "#                     epochs=10, validation_data=(np.array(x_val), np.array(y_val)))\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "    history = model.fit(np.array(x_train), np.array(y_train),\n",
    "                        epochs=10, validation_data=(np.array(x_val), np.array(y_val)))\n",
    "\n",
    "y_pred = model.predict(np.array(data_test))\n",
    "report(history, y_pred, labels_test)\n",
    "\n",
    "model.save('./models/instrument_model/1/', save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
